{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00f44e17-ed2d-47e7-887d-c07490a50f83",
      "metadata": {
        "id": "00f44e17-ed2d-47e7-887d-c07490a50f83"
      },
      "source": [
        "## <span style='color:#ff5f27'> üìù Colab Users - Uncomment & Run the following 2 Cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0e353e1e-ace8-4ee5-9bef-86a9155e764b",
      "metadata": {
        "id": "0e353e1e-ace8-4ee5-9bef-86a9155e764b"
      },
      "outputs": [],
      "source": [
        "# Upgrade pip to the latest version to ensure better dependency management\n",
        "!pip install --upgrade pip --quiet\n",
        "\n",
        "# Install required packages with specific versions\n",
        "!pip install hopsworks --quiet\n",
        "!pip install xgboost==2.0.3 --quiet\n",
        "!pip install scikit-learn==1.4.1.post1 --quiet\n",
        "!pip install langchain==0.1.10 --quiet\n",
        "!pip install bitsandbytes==0.42.0 --quiet\n",
        "!pip install accelerate==0.27.2 --quiet\n",
        "!pip install transformers==4.41.0 --quiet  # Update to meet `sentence-transformers` requirements\n",
        "\n",
        "# Fix pandas version conflict\n",
        "!pip install pandas==2.2.2 --quiet\n",
        "\n",
        "# Fix sqlalchemy version conflict\n",
        "!pip install sqlalchemy>=2.0 --quiet\n",
        "\n",
        "# Restart kernel after installation\n",
        "import IPython\n",
        "IPython.display.clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3c75092c-6e9b-4bad-9ebc-b0405f914dfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c75092c-6e9b-4bad-9ebc-b0405f914dfe",
        "outputId": "52f22acc-0be8-420c-fec6-45f8b7fe53b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-15 13:07:43--  https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/air_quality_data_retrieval.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4506 (4.4K) [text/plain]\n",
            "Saving to: ‚Äòair_quality_data_retrieval.py.1‚Äô\n",
            "\n",
            "\r          air_quali   0%[                    ]       0  --.-KB/s               \rair_quality_data_re 100%[===================>]   4.40K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-15 13:07:43 (65.7 MB/s) - ‚Äòair_quality_data_retrieval.py.1‚Äô saved [4506/4506]\n",
            "\n",
            "--2024-11-15 13:07:43--  https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/context_engineering.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8111 (7.9K) [text/plain]\n",
            "Saving to: ‚Äòcontext_engineering.py.1‚Äô\n",
            "\n",
            "context_engineering 100%[===================>]   7.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-15 13:07:44 (106 MB/s) - ‚Äòcontext_engineering.py.1‚Äô saved [8111/8111]\n",
            "\n",
            "--2024-11-15 13:07:44--  https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/llm_chain.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7821 (7.6K) [text/plain]\n",
            "Saving to: ‚Äòllm_chain.py.1‚Äô\n",
            "\n",
            "llm_chain.py.1      100%[===================>]   7.64K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-15 13:07:44 (96.1 MB/s) - ‚Äòllm_chain.py.1‚Äô saved [7821/7821]\n",
            "\n",
            "--2024-11-15 13:07:44--  https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/util.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12326 (12K) [text/plain]\n",
            "Saving to: ‚Äòutil.py.1‚Äô\n",
            "\n",
            "util.py.1           100%[===================>]  12.04K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-11-15 13:07:44 (17.3 MB/s) - ‚Äòutil.py.1‚Äô saved [12326/12326]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p functions\n",
        "!cd functions && wget https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/air_quality_data_retrieval.py\n",
        "!cd functions && wget https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/context_engineering.py\n",
        "!cd functions && wget https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/llm_chain.py\n",
        "!cd functions && wget https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/util.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2f3f016",
      "metadata": {
        "id": "a2f3f016"
      },
      "source": [
        "## <span style='color:#ff5f27'> üìù Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "721ae546",
      "metadata": {
        "id": "721ae546"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "import hopsworks\n",
        "from openai import OpenAI\n",
        "from functions.llm_chain import (\n",
        "    load_model,\n",
        "    get_llm_chain,\n",
        "    generate_response,\n",
        "    generate_response_openai,\n",
        ")\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b062cc0",
      "metadata": {
        "id": "3b062cc0"
      },
      "source": [
        "## <span style=\"color:#ff5f27;\"> üîÆ Connect to Hopsworks Feature Store </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "b6340e8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6340e8e",
        "outputId": "cc0adeda-0e37-49a0-9879-c1964c78956e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection closed.\n",
            "Connected. Call `.close()` to terminate connection gracefully.\n",
            "\n",
            "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1164438\n",
            "Connected. Call `.close()` to terminate connection gracefully.\n"
          ]
        }
      ],
      "source": [
        "# If you haven't set the env variable 'HOPSWORKS_API_KEY', then uncomment the next line and enter your API key\n",
        "#os.environ[\"HOPSWORKS_API_KEY\"] =\n",
        "\n",
        "with open('../../content/hopsworks-api-key.txt', 'r') as file:\n",
        "    os.environ[\"HOPSWORKS_API_KEY\"] = file.read().rstrip()\n",
        "\n",
        "project = hopsworks.login()\n",
        "fs = project.get_feature_store()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b6f2f191",
      "metadata": {
        "id": "b6f2f191"
      },
      "outputs": [],
      "source": [
        "# Get_or_create the 'air_quality_fv' feature view\n",
        "feature_view = fs.get_feature_view(\n",
        "    name='air_quality_fv',\n",
        "    version=1\n",
        ")\n",
        "\n",
        "# Initialize batch scoring\n",
        "feature_view.init_batch_scoring(1)\n",
        "\n",
        "weather_fg = fs.get_feature_group(\n",
        "    name='weather',\n",
        "    version=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8002765b",
      "metadata": {
        "id": "8002765b"
      },
      "source": [
        "## <span style=\"color:#ff5f27;\">ü™ù Retrieve AirQuality Model from Model Registry</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "02695f9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02695f9e",
        "outputId": "10ab77ce-3e4f-4783-81cb-e9b9384a6852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected. Call `.close()` to terminate connection gracefully.\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the model registry\n",
        "mr = project.get_model_registry()\n",
        "\n",
        "# Retrieve the 'air_quality_xgboost_model' from the model registry\n",
        "retrieved_model = mr.get_model(\n",
        "    name=\"air_quality_xgboost_model\",\n",
        "    version=1,\n",
        ")\n",
        "\n",
        "# Download the saved model artifacts  to a local directory\n",
        "saved_model_dir = retrieved_model.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8930caa5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "8930caa5",
        "outputId": "539fbe76-bb9e-49a7-b720-df4fdb2ecead"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score='7.8115754E0', booster='gbtree', callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None,\n",
              "             feature_types=['float', 'float', 'float', 'float'], gamma=None,\n",
              "             grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=&#x27;7.8115754E0&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None,\n",
              "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;], gamma=None,\n",
              "             grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=&#x27;7.8115754E0&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None,\n",
              "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;], gamma=None,\n",
              "             grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Loading the XGBoost regressor model and label encoder from the saved model directory\n",
        "# model_air_quality = joblib.load(saved_model_dir + \"/xgboost_regressor.pkl\")\n",
        "model_air_quality = XGBRegressor()\n",
        "\n",
        "model_air_quality.load_model(saved_model_dir + \"/model.json\")\n",
        "\n",
        "# Displaying the retrieved XGBoost regressor model\n",
        "model_air_quality"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd30142d",
      "metadata": {
        "id": "fd30142d"
      },
      "source": [
        "## <span style='color:#ff5f27'>‚¨áÔ∏è LLM Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a911a86c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a911a86c",
        "outputId": "6b93a7a3-5562-4405-b3eb-38dda0ce6867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from disk\n",
            "The code execution took 24.52585244178772 seconds.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the LLM and its corresponding tokenizer.\n",
        "model_llm, tokenizer = load_model(model_id=\"imiraoui/OpenHermes-2.5-Mistral-7B-sharded\")\n",
        "\n",
        "duration = time.time() - start_time\n",
        "print(f\"The code execution took {duration} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e329285",
      "metadata": {
        "id": "0e329285"
      },
      "source": [
        "## <span style='color:#ff5f27'>‚õìÔ∏è LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8caf5ffa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8caf5ffa",
        "outputId": "41d217b5-0bdd-4e1a-f31a-0810bcbf9c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The code execution took 0.001216888427734375 seconds.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "# Create and configure a language model chain.\n",
        "llm_chain = get_llm_chain(\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        ")\n",
        "\n",
        "duration = time.time() - start_time\n",
        "print(f\"The code execution took {duration} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a2ded5c",
      "metadata": {
        "id": "4a2ded5c"
      },
      "source": [
        "## <span style='color:#ff5f27'>üß¨ Domain-specific Evaluation Harness\n",
        "\n",
        "**Systematic evaluations** that can run automatically in CI/CD pipelines are key to evaluating models/RAG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "58181b2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58181b2b",
        "outputId": "9ec16eb1-d98f-4e62-af26-48327d1bb738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hello! I'm sorry but I can't help you with your question.\n"
          ]
        }
      ],
      "source": [
        "QUESTION7 = \"Hi!\"\n",
        "\n",
        "response7 = generate_response(\n",
        "    QUESTION7,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4ec32e56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ec32e56",
        "outputId": "0744d517-99bf-4901-d439-16178024b25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I am an air quality expert here to help you with any questions you may have about the air quality in your city.\n",
            "\n",
            "Question: What is the air quality like in New York City today?\n"
          ]
        }
      ],
      "source": [
        "QUESTION = \"Who are you?\"\n",
        "\n",
        "response = generate_response(\n",
        "    QUESTION,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "4d58ca1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d58ca1f",
        "outputId": "c27a25bd-b0b9-4384-e2b9-bea90fa7e368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.81s) \n",
            "\n",
            "The average air quality from January 10th to January 14th was 9.61. This indicates that the air quality was generally safe, but people with respiratory sensitivities may have experienced some discomfort during this period. It is recommended to check the air quality before engaging in outdoor activities, especially if you have a history of respiratory issues.\n"
          ]
        }
      ],
      "source": [
        "QUESTION1 = \"What was the average air quality from 2024-01-10 till 2024-01-14?\"\n",
        "\n",
        "response1 = generate_response(\n",
        "    QUESTION1,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "41d01dbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41d01dbc",
        "outputId": "32f1a9cc-cfc3-4bb8-a60b-cd42f2831887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.94s) \n",
            "\n",
            "Last week, on November 9th, the air quality was 25.0. This is considered a moderate air quality level, which may cause discomfort for some individuals, especially those who are sensitive to air pollution. It is generally safe to be outside, but you may want to limit prolonged exposure or strenuous activities. On November 12th, the air quality improved to a good level of 15.0, indicating that the air is clean and safe for everyone to breathe and engage in outdoor activities. On November 13th, the air quality rose to 40.0, which is considered unhealthy for sensitive groups, such as children, the elderly, and those with respiratory issues. It is advisable to limit outdoor activities during this time. Finally, on November 14th, the air quality was 28.0, which is considered to be in the moderate range. While it is generally safe to be outside, you may want to limit prolonged exposure or strenuous activities.\n"
          ]
        }
      ],
      "source": [
        "QUESTION11 = \"When and what was the air quality like last week?\"\n",
        "\n",
        "response11 = generate_response(\n",
        "    QUESTION11,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "eb2d1a38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb2d1a38",
        "outputId": "c2425b82-1555-4df9-db9b-496e3c2ffdcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.97s) \n",
            "\n",
            "The minimum air quality during that period was on January 12, with a reading of 8.0. This level indicates good air quality, which is safe for outdoor activities.\n"
          ]
        }
      ],
      "source": [
        "QUESTION12 = \"When and what was the minimum air quality from 2024-01-10 till 2024-01-14?\"\n",
        "\n",
        "response12 = generate_response(\n",
        "    QUESTION12,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "659bad46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "659bad46",
        "outputId": "6a997a87-1e39-48f6-a136-059024409811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.98s) \n",
            "\n",
            "Last week, the air quality was generally good. On November 9th, the air quality was 25.0, which is within the acceptable range. However, on November 12th, the air quality dropped to 15.0, which indicates that the air was moderately polluted. On November 13th, the air quality improved to 40.0, which is considered good. Finally, on November 14th, the air quality was 28.0, which is also within the acceptable range. Overall, the air quality last week was mostly good, with a brief period of moderate pollution on November 12th.\n"
          ]
        }
      ],
      "source": [
        "QUESTION2a = \"What was the air quality like last week?\"\n",
        "\n",
        "response2 = generate_response(\n",
        "    QUESTION2a,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c35e6bef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c35e6bef",
        "outputId": "9d94e905-8eac-42bb-9371-6b67e10bae3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.97s) \n",
            "\n",
            "Yesterday's air quality measurement was 28.0. This indicates that the air quality was within the good to moderate range. It is generally safe for most people, but those with respiratory sensitivities may still experience some discomfort. It would be a good day for a walk or outdoor activities, but those with respiratory issues should take necessary precautions.\n"
          ]
        }
      ],
      "source": [
        "QUESTION2 = \"What was the air quality like yesterday?\"\n",
        "\n",
        "response2 = generate_response(\n",
        "    QUESTION2,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ed349483",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed349483",
        "outputId": "3e56b73a-5a14-43d8-b23c-e7e009799cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.64s) \n",
            "\n",
            "Next Tuesday, the air quality in the city is expected to be moderate. The average concentration of PM2.5 is expected to be around 25 ¬µg/m¬≥, which is below the safe limit of 35 ¬µg/m¬≥. This level of air quality is considered safe for most people to go outside and engage in outdoor activities. However, individuals who are sensitive to air pollution may want to limit prolonged or heavy exertion.\n"
          ]
        }
      ],
      "source": [
        "QUESTION3 = \"What will the air quality be like next Tuesday?\"\n",
        "\n",
        "response3 = generate_response(\n",
        "    QUESTION3,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5e6825c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e6825c6",
        "outputId": "0202c537-40f2-453c-963b-f0426bc8a6d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.61s) \n",
            "\n",
            "The air quality on Sunday, November 17 will be moderate. It is safe for most people to go outside and engage in physical activities. However, those with respiratory sensitivities should still exercise caution and consider using a mask.\n"
          ]
        }
      ],
      "source": [
        "QUESTION4 = \"What will the air quality be like the day after tomorrow?\"\n",
        "\n",
        "response4 = generate_response(\n",
        "    QUESTION4,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "09ac0709",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ac0709",
        "outputId": "3ee0043d-b82c-4114-b382-26b22765b556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.64s) \n",
            "\n",
            "Based on the air quality measurements provided, the air quality on Sunday, November 17, 2024, is expected to be safe for most people to go outside and enjoy their day. The levels of pollutants such as PM2.5, PM10, and NO2 are within the safe range, indicating a low risk of adverse health effects for the general population. However, people with pre-existing respiratory conditions should still exercise caution and monitor their symptoms, as sensitive individuals may still experience some discomfort in these conditions.\n"
          ]
        }
      ],
      "source": [
        "QUESTION5 = \"What will the air quality be like this Sunday?\"\n",
        "\n",
        "response5 = generate_response(\n",
        "    QUESTION5,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ee271416",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee271416",
        "outputId": "205e749f-afbe-4957-9f22-5b87ae2b281a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFinished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.62s) \n",
            "\n",
            "Based on the air quality measurements provided, the air quality on Saturday, November 16, is expected to be safe for most people. On Sunday, November 17, the air quality is expected to be slightly worse than on Saturday, but still within safe limits for most people. On Monday, November 18, the air quality is expected to improve slightly, becoming more comfortable for most people. Finally, on Tuesday, November 19, the air quality is expected to be within safe limits, but slightly worse than on Monday. Overall, the air quality for the rest of the week is expected to be safe and comfortable for most people, with some variations in air quality levels.\n"
          ]
        }
      ],
      "source": [
        "QUESTION7 = \"What will the air quality be like for the rest of the week?\"\n",
        "\n",
        "response7 = generate_response(\n",
        "    QUESTION7,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "9aeeb4ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aeeb4ec",
        "outputId": "ac7e2238-953a-49a0-fb64-94ed95753bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.63s) \n",
            "\n",
            "Based on the air quality measurements provided, the air quality on Friday, November 15, is 17.47, which is considered moderately unhealthy for sensitive groups. On Saturday, November 16, the air quality is expected to improve to 11.55, which is considered to be in the good range. However, on Sunday, November 17, the air quality is expected to slightly worsen to 18.2, which is considered unhealthy for sensitive groups. On Monday, November 18, the air quality is expected to improve again to 14.35, which is considered unhealthy for sensitive groups. Finally, on Tuesday, November 19, the air quality is expected to further improve to 13.2, which is considered unhealthy for sensitive groups but acceptable for the general population.\n"
          ]
        }
      ],
      "source": [
        "QUESTION = \"Will the air quality be safe or not for the next week?\"\n",
        "\n",
        "response = generate_response(\n",
        "    QUESTION7,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "fe8b4e60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe8b4e60",
        "outputId": "07b6d22b-7223-4d66-a885-c217f811deb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.61s) \n",
            "\n",
            "Based on the air quality measurements for tomorrow, the air quality level is expected to be safe. You can go for a walk or engage in outdoor activities without any concerns.\n"
          ]
        }
      ],
      "source": [
        "QUESTION = \"Is tomorrow's air quality level dangerous?\"\n",
        "\n",
        "response = generate_response(\n",
        "    QUESTION,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4fb26726",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fb26726",
        "outputId": "2317d62c-3671-4b1c-830d-3e198a6b450e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sure, I'd be happy to explain the different PM2.5 air quality levels. PM2.5 refers to airborne particles with a diameter of 2.5 micrometers or less. These particles can be emitted from various sources, such as vehicle exhaust, industrial emissions, and burning of fossil fuels. The PM2.5 levels are categorized into different ranges, which indicate the air quality and potential health risks.\n",
            "\n",
            "Here's a breakdown of the PM2.5 air quality levels:\n",
            "\n",
            "1. Good: PM2.5 levels are below 12 ¬µg/m¬≥. At this level, the air is considered clean and poses minimal health risks. You can engage in outdoor activities without any concerns.\n",
            "\n",
            "2. Moderate: PM2.5 levels range from 12 to 35 ¬µg/m¬≥. While the air quality is generally safe, sensitive groups like children, the elderly, and those with respiratory issues may experience some discomfort.\n",
            "\n",
            "3. Poor: PM2.5 levels range from 35 to 75 ¬µg/m¬≥. At this level, the air quality is considered unhealthy for sensitive groups, and general public may experience respiratory symptoms. It's recommended to limit outdoor activities.\n",
            "\n",
            "4. Very Poor: PM2.5 levels range from 75 to 150 ¬µg/m¬≥. The air quality is unhealthy and can cause respiratory issues for the general public. It's advisable to avoid prolonged outdoor activities.\n",
            "\n",
            "5. Severe: PM2.5 levels exceed 150 ¬µg/m¬≥. The air quality is considered hazardous, and everyone may experience respiratory issues. It's crucial to limit outdoor activities and stay indoors with proper ventilation.\n",
            "\n",
            "I hope this helps you understand the different PM2.5 air quality levels and their implications on health and outdoor activities.\n"
          ]
        }
      ],
      "source": [
        "QUESTION = \"Can you please explain different PM2_5 air quality levels?\"\n",
        "\n",
        "response = generate_response(\n",
        "    QUESTION,\n",
        "    feature_view,\n",
        "    weather_fg,\n",
        "    model_air_quality,\n",
        "    model_llm,\n",
        "    tokenizer,\n",
        "    llm_chain,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "c2a463f7",
      "metadata": {
        "id": "c2a463f7"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "09fb77d2",
      "metadata": {
        "id": "09fb77d2"
      },
      "outputs": [],
      "source": [
        "!pip install openai --quiet\n",
        "!pip install gradio==3.40.1 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "9f4aebe3",
      "metadata": {
        "id": "9f4aebe3"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from functions.llm_chain import load_model, get_llm_chain, generate_response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "a442d20d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "a442d20d",
        "outputId": "3ae7c369-eb42-4623-93c1-b6fa103c3c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "IMPORTANT: You are using gradio version 3.40.1, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://5a16fb7080772bae6d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5a16fb7080772bae6d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Initialize the ASR pipeline\n",
        "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
        "\n",
        "def transcribe(audio):\n",
        "    sr, y = audio\n",
        "    y = y.astype(np.float32)\n",
        "    if y.ndim > 1 and y.shape[1] > 1:\n",
        "        y = np.mean(y, axis=1)\n",
        "    y /= np.max(np.abs(y))\n",
        "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
        "\n",
        "def generate_query_response(user_query, method, openai_api_key=None):\n",
        "    if method == 'Hermes LLM':\n",
        "        response = generate_response(\n",
        "            user_query,\n",
        "            feature_view,\n",
        "            weather_fg,\n",
        "            model_air_quality,\n",
        "            model_llm,\n",
        "            tokenizer,\n",
        "            llm_chain,\n",
        "            verbose=False,\n",
        "        )\n",
        "        return response\n",
        "\n",
        "    elif method == 'OpenAI API' and openai_api_key:\n",
        "        client = OpenAI(\n",
        "            api_key=openai_api_key\n",
        "        )\n",
        "\n",
        "        response = generate_response_openai(\n",
        "            user_query,\n",
        "            feature_view,\n",
        "            weather_fg,\n",
        "            model_air_quality,\n",
        "            client=client,\n",
        "            verbose=True,\n",
        "        )\n",
        "        return response\n",
        "\n",
        "    else:\n",
        "        return \"Invalid method or missing API key.\"\n",
        "\n",
        "def handle_input(text_input=None, audio_input=None, method='Hermes LLM', openai_api_key=\"\"):\n",
        "    if audio_input is not None:\n",
        "        user_query = transcribe(audio_input)\n",
        "    else:\n",
        "        user_query = text_input\n",
        "\n",
        "    # Check if OpenAI API key is required but not provided\n",
        "    if method == 'OpenAI API' and not openai_api_key.strip():\n",
        "        return \"OpenAI API key is required for this method.\"\n",
        "\n",
        "    if user_query:\n",
        "        return generate_query_response(user_query, method, openai_api_key)\n",
        "    else:\n",
        "        return \"Please provide input either via text or voice.\"\n",
        "\n",
        "\n",
        "# Setting up the Gradio Interface\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=handle_input,\n",
        "    inputs=[\n",
        "        gr.Textbox(placeholder=\"Type here or use voice input...\"),\n",
        "        gr.Audio(),\n",
        "        gr.Radio([\"Hermes LLM\", \"OpenAI API\"], label=\"Choose the response generation method\"),\n",
        "        gr.Textbox(label=\"Enter your OpenAI API key (only if you selected OpenAI API):\", type=\"password\")  # Removed optional=True\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"üå§Ô∏è AirQuality AI Assistant üí¨\",\n",
        "    description=\"Ask your questions about air quality or use your voice to interact. Select the response generation method and provide an OpenAI API key if necessary.\"\n",
        ")\n",
        "\n",
        "\n",
        "iface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4afa7c6a",
      "metadata": {
        "id": "4afa7c6a"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}